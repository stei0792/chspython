{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "data = pd.read_csv(\"C:/Users/msteinme/Documents/allvariablesknownpartnofuturepredictiondates.csv\")\n",
    "df_96on = data[['Date','x_var1','x_var2',.....,'y_var']]\n",
    "df_96on.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#putting date into correct format\n",
    "from datetime import datetime\n",
    "df_96on['Date'] = pd.to_datetime(df_96on['Date'])\n",
    "date = df_96on['Date']\n",
    "df_96on.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#describe all the variables, count, mean, etc\n",
    "df_96on.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# include vartiables you want to look at, sometimes have to make multiple boxplots so that\n",
    "# you can see correct scaling of variables \n",
    "plt.show(df_96on[['x_var1',....,'y_var']].plot(kind='box',figsize=(8,8),title=('BoxPlot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#correlation of variables\n",
    "df_96on.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#heat map\n",
    "cols= ['x_var1',....,'y_var']\n",
    "cm = np.corrcoef(df_96on[cols].values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "hm=sns.heatmap(cm,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size':15},yticklabels=cols,xticklabels=cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scatterplot matrix\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "sns.pairplot(df_96on, size=2.5);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trend, just modify to look at the different variables and scaling\n",
    "# the *_ is just scaling it\n",
    "x = date\n",
    "y1 = (df_96on['x_var1'])\n",
    "y2 = (df_96on['x_var2'])*3000\n",
    "y3 = (df_96on['y_var'])*1000\n",
    "\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x,y1,'g')\n",
    "ax.plot(x,y2,'y')\n",
    "ax.plot(x,y3,'b')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "ax.set_title('______ to Predict Urea 96-5/30/2016', size=(30))\n",
    "ax.tick_params(axis='x',which='major',labelsize=15)\n",
    "ax.tick_params(axis='y',which='major',labelsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at different MLR's since different X variables highly correlated to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MLR model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "#fit a OLS model with all, see how R^2 changes\n",
    "X = df_96on[['x_var1',....]]\n",
    "Y = df_96on[['y_var']]\n",
    "X= sm.add_constant(X)\n",
    "est= sm.OLS(Y,X).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Selection (want lowest AIC and p-values no greater than 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_var1\n",
    "X = df_96on[['x_var1']]\n",
    "Y = df_96on[['y_var']]\n",
    "X= sm.add_constant(X)\n",
    "est= sm.OLS(Y,X).fit()\n",
    "print(est.aic)\n",
    "print(est.pvalues)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_var2\n",
    "X = df_96on[['x_var2']]\n",
    "Y = df_96on[['y_var']]\n",
    "X= sm.add_constant(X)\n",
    "est= sm.OLS(Y,X).fit()\n",
    "print(est.aic)\n",
    "print(est.pvalues)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_var3\n",
    "X = df_96on[['x_var3']]\n",
    "Y = df_96on[['y_var']]\n",
    "X= sm.add_constant(X)\n",
    "est= sm.OLS(Y,X).fit()\n",
    "print(est.aic)\n",
    "print(est.pvalues)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 now using 2 variables (let's say var_1 had lowest AIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_var1 & x_var2\n",
    "X = df_96on[['x_var1','x_var2']]\n",
    "Y = df_96on[['y_var']]\n",
    "X= sm.add_constant(X)\n",
    "est= sm.OLS(Y,X).fit()\n",
    "print(est.aic)\n",
    "print(est.pvalues)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_var1 & x_var3\n",
    "X = df_96on[['x_var1','x_var3']]\n",
    "Y = df_96on[['y_var']]\n",
    "X= sm.add_constant(X)\n",
    "est= sm.OLS(Y,X).fit()\n",
    "print(est.aic)\n",
    "print(est.pvalues)\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### keep adding variables until AIC no longer decreases or some of the p-values don't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "X = df_96on[['x_var1','x_var2',....]].values\n",
    "y = df_96on['y_var'].values\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#below is how to find best parameters\n",
    "from sklearn import metrics\n",
    "from sklearn import grid_search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def fit_predict_model(X_train,y_train,):\n",
    "    \"\"\"Find and tune the optimal model. Make a prediction on urea data\"\"\"\n",
    "    \n",
    "    # Setup a Random Forest Regressor\n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    parameters = {'n_estimators':(100,125,150,175,200),\n",
    "                  'max_depth':(5,6,7,8,9,10)}\n",
    "\n",
    "    mse_scorer = metrics.make_scorer(metrics.mean_squared_error, greater_is_better = False)\n",
    "    \n",
    "    # use grid search to fine tune the RandomForests Regressor and\n",
    "    # obtain the parameters that generate the best training performance. \n",
    "    reg = grid_search.GridSearchCV(regressor, param_grid=parameters,\n",
    "                                   scoring=mse_scorer, cv = 10)\n",
    "    \n",
    "    # Fit the learner to the training data to obtain the best parameter set\n",
    "    print (\"Final Model: \")\n",
    "    print (reg.fit(X_train, y_train))\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do multiple times to see what parameters are the best\n",
    "# it will print off best parameters in 2nd paragraph and copy that and paste it after RandomForestRegressor\n",
    "rdf_model_ureaall = fit_predict_model(X_train,y_train)\n",
    "print (rdf_model_ureaall.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 = All variables used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = df_96on[['x_var1',.....]].values\n",
    "y1 = df_96on['y_var'].values\n",
    "X_train1, X_test1, y_train1, y_test1= train_test_split(X1,y1,test_size=0.3,random_state=1)\n",
    "forest1 = RandomForestRegressor<insert paragraph 2 from above cell, should be in parenthesis>\n",
    "forest1.fit(X_train1, y_train1)\n",
    "y_train_pred1= forest1.predict(X_train1)\n",
    "y_test_pred1= forest1.predict(X_test1)\n",
    "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train1, y_train_pred1),mean_squared_error(y_test1, y_test_pred1)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train1, y_train_pred1),r2_score(y_test1,y_test_pred1)))\n",
    "print(forest1.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 blank x_var not used (this model should be important features, then after can make models with different combos, for ex all variables not correlated with each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no x_var1 since not important\n",
    "X = df_96on[['x_var2','x_var3',....]].values\n",
    "y = df_96on['y_var'].values\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#do multiple times to find best parameters\n",
    "rdf_model_ureanox_var1 = fit_predict_model(X_train,y_train)\n",
    "print (rdf_model_ureanox_var1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remember for each model change numbers after x, y, x_train, x_test, etc\n",
    "X2 = df_96on[['x_var2','x_var3',....]].values\n",
    "y2 = df_96on['y_var'].values\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,test_size=0.3,random_state=1)\n",
    "forest2 = RandomForestRegressor<insert paragraph2 from output above>\n",
    "forest2.fit(X_train2, y_train2)\n",
    "y_train_pred2 = forest2.predict(X_train2)\n",
    "y_test_pred2 = forest2.predict(X_test2)\n",
    "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train2, y_train_pred2),mean_squared_error(y_test2, y_test_pred2)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train2, y_train_pred2),r2_score(y_test2,y_test_pred2)))\n",
    "print(forest2.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "data = pd.read_csv(\"C:/Users/msteinme/Documents/avgfile_thathas_modeldates_and_futurepredictionpart.csv\")\n",
    "df_96on = data[['Date','x_var1','x_var2',...,'y_var']][0:1062] #only include model part not future prediction part\n",
    "df_96on.tail() #can see if you have correct part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df_96on['Date'] = pd.to_datetime(df_96on['Date'])\n",
    "date = df_96on['Date']\n",
    "print (df_96on.dtypes)\n",
    "df_96on.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLR Models I will use (found in Exploratory Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDF Models I will use (found in Exploratory Analysis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = df_96on[['x_var1','x_var2',.....]].values\n",
    "y1 = df_96on['y_var'].values\n",
    "X_train1, X_test1, y_train1, y_test1= train_test_split(X1,y1,test_size=0.3,random_state=1)\n",
    "forest1 = RandomForestRegressor<instert first part in exploratory analysis>\n",
    "forest1.fit(X_train1, y_train1)\n",
    "y_train_pred1= forest1.predict(X_train1)\n",
    "y_test_pred1= forest1.predict(X_test1)\n",
    "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train1, y_train_pred1),mean_squared_error(y_test1, y_test_pred1)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train1, y_train_pred1),r2_score(y_test1,y_test_pred1)))\n",
    "print(forest1.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2 = df_96on[['x_var2',...]].values\n",
    "y2 = df_96on['y_var'].values\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2,y2,test_size=0.3,random_state=1)\n",
    "forest2 = RandomForestRegressor<insert 2nd part in exploratory analysis>\n",
    "forest2.fit(X_train2, y_train2)\n",
    "y_train_pred2 = forest2.predict(X_train2)\n",
    "y_test_pred2 = forest2.predict(X_test2)\n",
    "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train2, y_train_pred2),mean_squared_error(y_test2, y_test_pred2)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train2, y_train_pred2),r2_score(y_test2,y_test_pred2)))\n",
    "print(forest2.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comparing models that will be used\n",
    "model1 = forest1.predict(X1)\n",
    "model2 = forest2.predict(X2)\n",
    "model1 = pd.DataFrame(model1)\n",
    "model2 = pd.DataFrame(model2)\n",
    "\n",
    "#example mlr 22.1919 is coefficient, other numbers correspond to certain x_vars\n",
    "mlr1 = 22.1919 + (df_96on['x_var1']*1.6482) + (df_96on['x_var2']*0.1470) \n",
    "df_96on['MLR1'] = mlr1\n",
    "\n",
    "df_96on['Model1'] = model1\n",
    "df_96on['Model2'] = model2\n",
    "df_96on.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions section 6/1/2016 - 12/31/2020 for example\n",
    "newpred = data[['Date','x_var1',....]][1062:2768] #include all variables will use except y_var & include date\n",
    "newpred1 = data [['x_var1','x_var2',...]][1062:2768]  #goes with model 1\n",
    "newpred2 = data[[...]][1062:2768] #goes with model 2\n",
    "newpred3 = data[[...]][1062:2768]  #goes with model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#each of the models added to predictions data part\n",
    "newpred = np.array(newpred)\n",
    "newpred = pd.DataFrame(newpred)\n",
    "newpred.columns = ['Date','x_var1','x_var2',...] #all variables used except urea\n",
    "newpred_predicted1 = forest1.predict(newpred1) #goes with model 1\n",
    "df_new_pred1 = pd.DataFrame(newpred_predicted1)\n",
    "newpred['Model1'] = df_new_pred1\n",
    "\n",
    "newpred['Date'] = pd.to_datetime(newpred['Date'])\n",
    "newpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model 2\n",
    "newpred_predicted2 = forest2.predict(newpred2)\n",
    "df_new_pred2 = pd.DataFrame(newpred_predicted2)\n",
    "newpred['Model2'] = df_new_pred2\n",
    " #same as mlr above except use newpred instead of df_96on\n",
    "mlrpredicted1 = 22.1919 + (newpred['x_var1']*1.6482) + (newpred['x_var2']*0.1470)\n",
    "newpred['MLR1'] = mlrpredicted1\n",
    "newpred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combining known with predicted\n",
    "frames = [df_96on,newpred2]\n",
    "combined = pd.concat(frames)\n",
    "combined.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = combined[['Date','x_var1','x_var2'...,'y_var','MLR1','Model1','Model2',...]] #all variables and model name too\n",
    "combined = np.array(combined)\n",
    "combined = pd.DataFrame(combined)\n",
    "combined.columns = ['Date','Crude','Corn','My_Coal','Gas','Urea_Inventory','Urea','Urea_Pred_MLR_Top3','Urea_Pred_MLR_Suggested','Urea_Pred_MLR_Suggested2','Urea_Pred_RDF_Top3','Urea_Pred_RDF_Suggested','Urea_Pred_RDF_Suggested2']\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#saving combined file as csv\n",
    "combined.to_csv(\"C:/Users/msteinme/Documents/blahblah_avg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Into Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#putting combined data into monthly format\n",
    "combined.index = combined['Date'].values\n",
    "combined = combined.drop(['Date'],axis=1)\n",
    "combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = combined.resample('MS',how='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save monthly format as csv\n",
    "df.to_csv(\"C:/Users/msteinme/Documents/blahblah_monthly_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#looking at actual vs predicted monthly\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "y1 = (df['y_var'])\n",
    "y2 = (df['Model1'])\n",
    "y3 = (df['Model2'])\n",
    "y4 = (df['Model3'])\n",
    "y5 = (df['Model4'])\n",
    "y6 =(df['Model5'])\n",
    "y7 = (df['Model6'])\n",
    "\n",
    "fig = plt.figure(figsize=(18,12))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(y1,'r')\n",
    "ax.plot(y2,'lightgreen')\n",
    "ax.plot(y3,'g')\n",
    "ax.plot(y4,'m')\n",
    "ax.plot(y5,'b')\n",
    "ax.plot(y6,'orange')\n",
    "ax.plot(y7,'y')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "ax.set_title('Actual vs Predicted Monthly y_var (Average Case)', size=(30))\n",
    "ax.tick_params(axis='x',which='major',labelsize=15)\n",
    "ax.tick_params(axis='y',which='major',labelsize=15)\n",
    "ax.set_ylabel('Urea',size=(20))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Avg section stuff and change saved files for Best and Worst and imported files should be different too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worst Case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
